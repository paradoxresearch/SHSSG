# Using Docker Compose

## Contents

- [Using Docker Compose](#using-docker-compose)
  - [Contents](#contents)
  - [Introduction](#introduction)
    - [Understanding Docker Compose Basics](#understanding-docker-compose-basics)
    - [Installing Docker Compose](#installing-docker-compose)
  - [Creating a Simple Docker Compose Project](#creating-a-simple-docker-compose-project)
    - [Creating a Basic `docker-compose.yml` File](#creating-a-basic-docker-composeyml-file)
    - [Common Docker Compose Commands](#common-docker-compose-commands)
  - [Advanced Docker Compose Concepts](#advanced-docker-compose-concepts)
    - [Define and Use Volumes for Persistent Data Storage](#define-and-use-volumes-for-persistent-data-storage)
    - [Network Configurations Within Docker Compose](#network-configurations-within-docker-compose)
    - [Introduce Environment Variables in Docker Compose](#introduce-environment-variables-in-docker-compose)
  - [Practical Application and Troubleshooting](#practical-application-and-troubleshooting)
    - [Example Application](#example-application)
    - [Troubleshooting](#troubleshooting)

## Introduction

### Understanding Docker Compose Basics

Docker Compose is a tool developed by Docker, Inc. that facilitates the definition and running of multi-container Docker applications. Think of it as an orchestration tool for local development and testing environments.

**Purpose and Benefits**:

- **Simplification**: Instead of managing individual Docker containers, networks, and volumes with separate `docker run` commands, Docker Compose allows you to define an entire application stack in a single file. This drastically reduces complexity.
- **Reproducibility**: The `docker-compose.yml` file acts as a blueprint for your application's architecture. This ensures that anyone (or any system) can spin up the exact same environment with a single command, promoting consistency across development, testing, and even production environments.
- **Efficiency**: For applications comprised of multiple services (e.g., a web server, a database, and a backend API), Docker Compose streamlines the startup, shutdown, and linking of these services.

**The** `docker-compose.yml` **File**:

This is the core of Docker Compose. It's a YAML (*YAML Ain't Markup Language* or *Yet another markup language*) file where you define the services that make up your application, along with their configurations. Here are the fundamental top-level sections you'll typically find:

- `services`: This is where you define each individual container that is part of your application. For example, you might have a service for your web server (e.g., Nginx or Apache), another for your database (e.g., PostgreSQL or MySQL), and another for your application's backend. Each service typically specifies:

  - The Docker image to use (e.g., `nginx:latest`, `mysql:8.0`).
  - Port mappings (e.g., `- "80:80"` to expose port 80).
  - Volume mounts (e.g., `- ./data:/var/lib/mysql` for persistent data).
  - Environment variables.
  - Dependencies on other services.

- `networks`: This section allows you to define custom networks for your services. By default, Docker Compose creates a default network for your project, allowing services to communicate with each other using their service names as hostnames. However, defining custom networks provides more control over network isolation and communication.

- `volumes`: This section is used to define named volumes, which are the preferred mechanism for persisting data generated by Docker containers. Unlike bind mounts (where data is stored directly on the host filesystem), named volumes are managed by Docker and are more portable.

Imagine you're building a house. Instead of buying each brick, window, and door separately and assembling them by hand every time you want to build the same house, Docker Compose is like having a detailed architectural plan (the `docker-compose.yml` file) that tells a pre-fabrication factory exactly how to assemble all the different components into a complete, functional house.

### Installing Docker Compose

The installation of Docker Compose primarily involves command-line operations. Docker Compose is not typically included in the standard repositories, so we often obtain it directly from the official GitHub releases.

Here are the general steps for installing Docker Compose, focusing on the command-line approach:

1. **Check for existing Docker installation**: Before installing Docker Compose, ensure that Docker Engine is already installed and running on your Ubuntu Server. Docker Compose relies on a functional Docker daemon. You can verify this with:

    ```Bash
    sudo systemctl status docker
    ```

    If Docker is not installed, you would typically install it via the official Docker repository, but we will assume for this lesson that Docker Engine is already in place.

2. **Download the Docker Compose binary**: The recommended method is to download the latest stable release of Docker Compose from its GitHub repository. You can find the latest version number on the Docker Compose GitHub releases page. For instance, to download version `v2.24.5` (please verify the latest version on the GitHub page as versions are frequently updated):

    ```Bash
    sudo curl -L "https://github.com/docker/compose/releases/download/v2.24.5/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
    ```

   - `curl -L`: Downloads the file and follows redirects.
   - `$(uname -s)`: Substitutes the operating system kernel name (e.g., `Linux`).
   - `$(uname -m)`: Substitutes the machine hardware name (e.g., `x86_64`).
   - `-o /usr/local/bin/docker-compose`: Specifies the output file path and name. `/usr/local/bin` is a common directory for manually installed executable programs.

3. **Apply executable permissions**: After downloading, the binary needs executable permissions to be run as a command:

    ```Bash
    sudo chmod +x /usr/local/bin/docker-compose
    ```

    This command adds execute permission for the owner, group, and others.

4. **Verify the installation**: You can confirm that Docker Compose is installed correctly and is accessible in your PATH by checking its version:

    ```Bash
    docker-compose --version
    ```

    This command should output the installed Docker Compose version.

It's important to understand that `docker-compose` is a standalone binary that interacts with the Docker daemon. It doesn't run inside a container itself; rather, it *orchestrates* containers.

## Creating a Simple Docker Compose Project

### Creating a Basic `docker-compose.yml` File

Now, let's create our first `docker-compose.yml` file. This file will define a simple web server using Nginx, which is a popular open-source web server. The goal is to serve a basic "Hello, World!" web page.

To begin, you will need to create a project directory and navigate into it. This is where your `docker-compose.yml` file and any related application files will reside.

```Bash
mkdir my_nginx_app
cd my_nginx_app
```

Next, we will create a simple `index.html` file that Nginx will serve.

```Bash
echo "<h1>Hello from Docker Compose!</h1>" > index.html
```

Now, let's create the `docker-compose.yml` file. You can use a command-line text editor like `nano` or `vim`.

```Bash
nano docker-compose.yml
```

Inside `nano` (or `vim`), paste the following content:

```YAML
version: '3.8'

services:
  web:
    image: nginx:latest
    ports:
      - "80:80"
    volumes:
      - ./index.html:/usr/share/nginx/html/index.html
```

Let's break down this file line by line:

- `version: '3.8'`: This specifies the Docker Compose file format version. Using a recent version like `3.8` (or higher, check Docker's documentation for the latest recommended version) ensures access to the latest features.
- `services:`: As discussed previously, this is the top-level key where you define all the individual services (containers) that make up your application.
- `web:`: This is the name we've given to our service. You can name your services anything you like, but descriptive names are best. This name will also be used for internal DNS resolution within your Docker Compose network.
- `image: nginx:latest`: This tells Docker Compose to use the `nginx` Docker image, specifically the `latest` tag. If the image is not found locally, Docker will automatically pull it from Docker Hub.
- `ports:`: This section maps ports between the host machine (your server) and the container.
  - `"80:80"`: This means "map port 80 on the host to port 80 inside the container." So, when you access `http://your_server_ip:80` (or just `http://your_server_ip` if port 80 is default), the request will be forwarded to the Nginx server running inside the `web` container.
- `volumes:`: This section is for mounting volumes. We are using a bind mount here.
  - `- ./index.html:/usr/share/nginx/html/index.html`: This tells Docker Compose to take the `index.html` file from your current directory (`./index.html`) on the host machine and mount it directly into the Nginx container at `/usr/share/nginx/html/index.html`. This is the default location where Nginx looks for its `index.html` file to serve. This means any changes you make to your local `index.html` file will be reflected in the running container.

This configuration defines a single service, `web`, which will run an Nginx container and serve our custom `index.html` file. It's a fundamental example, but it illustrates how services, images, ports, and volumes are combined.

### Common Docker Compose Commands

Now that we have our `docker-compose.yml` file, we can use it to manage our simple web application. These commands are executed from the directory where your `docker-compose.yml` file is located.

1. `docker compose up`: This is the primary command to start your Docker Compose application.

   - **Purpose**: It builds, (re)creates, starts, and attaches to containers for all services defined in your `docker-compose.yml` file. If images are not locally available, it will pull them. If changes have been made to service definitions or Dockerfiles, it will rebuild images.
   - **Usage**:

        ```Bash
        docker compose up
        ```

        When run without any flags, it will output logs from all services to your terminal. This is useful for development and debugging. To run the services in the background (detached mode), which is more common for production or continuous operation on a server, use the -d flag:

        ```Bash
        docker compose up -d
        ```

        After running `docker compose up -d`, you should be able to access your Nginx web server by navigating your web browser to the IP address of your server. For example, if your server's IP is `192.168.1.100`, you would visit `http://192.168.1.100`. You should see "Hello from Docker Compose!"

2. `docker compose ps`: This command lists the containers started by Docker Compose.

   - **Purpose**: It shows the status of the services defined in your `docker-compose.yml` file. This is analogous to `docker ps` but filtered specifically for your Compose project.
   - **Usage**:

        ```Bash
        docker compose ps
        ```

        You will see information such as the service name, command, state (e.g., `Up`), and ports.

3. `docker compose logs`: This command displays log output from services.

   - **Purpose**: Useful for debugging and monitoring, it shows the standard output and standard error streams from your running containers.
   - **Usage**:

        ```Bash
        docker compose logs [SERVICE_NAME]
        ```

       - To view logs for all services: `docker compose logs`
       - To view logs for a specific service (e.g., our `web` service): `docker compose logs web`
       - To follow logs in real-time (like `tail -f`): `docker compose logs -f`

4. `docker compose down`: This command stops and removes containers, networks, and volumes.

   - **Purpose**: It tears down the entire application stack defined in your `docker-compose.yml` file. This is crucial for cleaning up your environment.
   - Usage:

        ```Bash
        docker compose down
        ```

        By default, it removes containers and networks. To also remove named `volumes` declared in the volumes section of the `docker-compose.yml` (though we haven't used named volumes in our simple example yet), you would add the `-v` flag:

        ```Bash
        docker compose down -v
        ```

These four commands form the fundamental cycle of deploying, monitoring, and tearing down a Docker Compose application. They are essential for any administrator working with multi-container setups.

## Advanced Docker Compose Concepts

### Define and Use Volumes for Persistent Data Storage

In the previous example, we used a bind mount to serve our `index.html`. While bind mounts are useful for development, for persistent data that your application generates (like database files, user uploads, or logs), **named volumes** are generally the preferred method in production environments.

**Why are volumes important for persistent data?**

By default, data inside a Docker container is ephemeral. This means that if the container is removed, all the data within it is lost. For applications that need to store data (like a database), this is problematic. Volumes provide a way to store data outside the container's filesystem, ensuring that the data persists even if the container is stopped, removed, or recreated.

**Types of Volumes**:

1. **Bind Mounts**: (As seen with `index.html`) These mount a file or directory from the host machine directly into the container. They are highly dependent on the host's directory structure and are often used for development (e.g., source code, configuration files).

   - Example from `docker-compose.yml`:

        ```YAML
        volumes:
          - ./my_data:/app/data
        ```

        This mounts the `my_data` directory from the current directory on the host to `/app/data` inside the container.

2. **Named Volumes**: These are managed by Docker. You create and manage them directly through Docker, and Docker stores them in a part of the host filesystem (typically `/var/lib/docker/volumes/` on Linux) that it controls. They are more abstract and portable than bind mounts because their exact location on the host doesn't need to be specified by the user.

   - **Defining a named volume in** `docker-compose.yml`: First, you declare the named volume at the top-level `volumes` section of your `docker-compose.yml` file:

        ```YAML
        version: '3.8'

        services:
          db:
            image: postgres:13
            volumes:
              - db_data:/var/lib/postgresql/data # Mount the named volume into the container
            environment:
              POSTGRES_DB: mydatabase
              POSTGRES_USER: user
              POSTGRES_PASSWORD: password

        volumes:
          db_data: # Declare the named volume here
        ```

        In this example:

        - We define a service `db` using the `postgres:13` image.
        - Inside the `db` service, we mount `db_data` (our named volume) to `/var/lib/postgresql/data` within the container. This is the default directory where PostgreSQL stores its database files.
        - At the bottom, under the top-level `volumes`: key, we declare `db_data:`. This tells Docker Compose to create a named volume called `db_data` if it doesn't already exist.

**Benefits of Named Volumes**:

- **Data Persistence**: Data outlives containers.
- **Portability**: The `docker-compose.yml` file doesn't need to know the host's specific directory structure.
- **Backup and Migration**: Easier to back up and migrate data.
- **Performance**: For some storage drivers, named volumes can offer better performance than bind mounts.

To illustrate, consider a database container. If you don't use a volume, every time you `docker compose down` and `docker compose up` again, your database would be empty. By using a named volume, the database files (and all your data) are stored persistently, so your data is still there when you restart the database service.

### Network Configurations Within Docker Compose

Effective networking is fundamental for multi-container applications to communicate with each other. Docker Compose simplifies this by creating a default network for your project, but it also provides robust options for custom network configurations.

**Default Network**:

When you run `docker compose up`, Docker Compose automatically creates a default network for your project. All services defined in your `docker-compose.yml` file are connected to this network.

- **Service Discovery**: Within this default network, services can communicate with each other using their service names as hostnames. For example, if you have a `web` service and a `db` service, your `web` service can connect to the `db` service simply by using `db` as the hostname and the appropriate port (e.g., `db:5432` for PostgreSQL). This internal DNS resolution is a powerful feature that simplifies inter-service communication.

**Custom Networks**:

While the default network is convenient, custom networks offer more control over network isolation and topology. You might use custom networks for:

- **Isolation**: To segment different parts of your application or to isolate specific services from others.
- **Existing Networks**: To connect your Docker Compose application to an existing Docker network that might be used by other non-Compose containers.
- **Advanced Topologies**: To create more complex network setups, though this is less common for typical applications.

To define a custom network, you add a top-level networks section to your docker-compose.yml file:

```YAML
version: '3.8'

services:
  web:
    image: nginx:latest
    ports:
      - "80:80"
    networks:
      - frontend_network # Connect 'web' to frontend_network

  api:
    image: my_api_image:latest
    networks:
      - frontend_network # Connect 'api' to frontend_network
      - backend_network  # Connect 'api' to backend_network

  db:
    image: postgres:13
    networks:
      - backend_network # Connect 'db' to backend_network

networks:
  frontend_network: # Declare the custom network
    driver: bridge # default driver, but can be specified
  backend_network: # Declare another custom network
    driver: bridge
```

**In this example**:

- We define two custom networks: `frontend_network` and `backend_network`.
- The `web` service is connected only to `frontend_network`.
- The `api` service is connected to both `frontend_network` (to receive requests from `web`) and `backend_network` (to communicate with `db`).
- The `db` service is connected only to backend_network.

This setup means `web` can talk to `api` (via `api` as a hostname), and `api` can talk to `db` (via `db` as a hostname). However, `web` cannot directly talk to `db` because they are not on a common network. This provides a clear separation.

**Service Linking (Deprecated Approach - Use Networks)**:

Historically, Docker Compose had a `links` keyword to enable services to discover each other. However, this method is largely considered legacy and **it is strongly recommended to use networks for inter-service communication and discovery** as demonstrated above. Networks provide more robust and flexible service discovery and isolation.

### Introduce Environment Variables in Docker Compose

Environment variables are a fundamental mechanism for configuring applications, both inside and outside of Docker containers. In the context of Docker Compose, they provide a flexible way to pass configuration settings to your services without hardcoding them into the `docker-compose.yml` file or the Docker images themselves. This is particularly useful for sensitive information (like database passwords), configurable parameters (like API keys or service URLs), or differentiating configurations between development, testing, and production environments.

There are several ways to use environment variables with Docker Compose:

1. **Directly in** `docker-compose.yml`: You can specify `environment` variables directly within the environment section of a service. This is suitable for non-sensitive or default values.

    ```YAML
    services:
      web:
        image: myapp:latest
        environment:
          - APP_MODE=production
          - API_URL=http://api.example.com
          - DEBUG_MODE=false
    ```

    In this example, the container for the `web` service will have `APP_MODE`, `API_URL`, and `DEBUG_MODE` environment variables set to the specified values.

2. **Using a** `.env` **file (recommended for sensitive data and separation)**: This is the most common and recommended approach, especially for sensitive information like database credentials or API keys. Docker Compose automatically looks for a file named `.env` in the same directory as your `docker-compose.yml` file. Variables defined in this `.env` file are then accessible within your `docker-compose.yml`.

    First, create a .env file in your project directory:

    ```Bash
    nano .env
    ```

    Then, add your variables to it (e.g., for a database):

    ```shell
    DB_USER=admin
    DB_PASSWORD=mysecretpassword123
    DB_NAME=myapp_db
    ```

    Now, in your `docker-compose.yml` file, you can reference these variables using the `${VARIABLE_NAME}` syntax:

    ```YAML
    version: '3.8'

    services:
      db:
        image: postgres:13
        environment:
          POSTGRES_USER: ${DB_USER}
          POSTGRES_PASSWORD: ${DB_PASSWORD}
          POSTGRES_DB: ${DB_NAME}
    ```

    When Docker Compose starts, it will substitute `${DB_USER}`, `${DB_PASSWORD}`, and `${DB_NAME}` with the values from your .env file. This is crucial for keeping sensitive information out of version control systems (like Git) and for easily changing configurations without modifying the `docker-compose.yml` file itself.

3. **Using an** `env_file` **property**: You can specify a custom environment file using the `env_file` property within a service definition. This is useful if you have multiple environment files for different scenarios or prefer a different naming convention.

    ```YAML

    services:
      app:
        image: myapp:latest
        env_file:
          - ./config/production.env
          - ./common.env
    ```

    Docker Compose will load variables from these files. Variables in later files override those in earlier ones.

**Benefits of using environment variables**:

- **Flexibility**: Easily change configurations without modifying service definitions.
- **Security**: Keep sensitive data out of your main configuration files and version control by using `.env` files.
- **Portability**: Different environments (development, staging, production) can use different `.env` files without changing the `docker-compose.yml`.

Think of environment variables as a set of instructions you whisper to your application containers right before they start. These instructions tell them how to behave in their specific environment, such as which database to connect to or what mode to run in.

## Practical Application and Troubleshooting

### Example Application

To solidify your understanding, let's build a more complete, albeit simplified, application stack using Docker Compose. This example will include:

- A **web service** (Nginx) acting as a reverse proxy.
- An **application service** (a simple Python Flask app) that the web server will forward requests to.
- A **database service** (PostgreSQL) that the application service will connect to.

This setup demonstrates how different services communicate and depend on each other.

First, let's prepare the necessary files:

1. **Create a project directory**:

    ```Bash
    mkdir complex_app
    cd complex_app
    ```

2. **Create a simple Flask application (app.py)**:

    ```Bash
    nano app.py
    ```

    **Paste the following Python code**:

    ```Python
    from flask import Flask
    import os

    app = Flask(__name__)

    @app.route('/')
    def hello():
        db_host = os.getenv('DB_HOST', 'localhost')
        db_port = os.getenv('DB_PORT', '5432')
        return f"Hello from Flask app! Connecting to database at {db_host}:{db_port}"

    if __name__ == '__main__':
        app.run(host='0.0.0.0', port=5000)
    ```

    This Flask app reads database host and port from environment variables, which we'll configure via Docker Compose.

3. **Create a requirements.txt for the Flask app**:

    ```Bash
    echo "Flask" > requirements.txt
    ```

4. **Create a Dockerfile for the Flask app**:

    ```Bash
    nano Dockerfile
    ```

    Paste the following content:

    ```Docker
    FROM python:3.9-slim-buster
    WORKDIR /app
    COPY requirements.txt .
    RUN pip install -r requirements.txt
    COPY app.py .
    CMD ["python", "app.py"]
    ```

    This Dockerfile builds an image for our Flask application.

5. **Create an Nginx configuration file (nginx.conf)**:

    ```Bash
    mkdir nginx
    nano nginx/nginx.conf
    ```

    **Paste the following Nginx configuration**:

    ```Nginx
    events {
        worker_connections 1024;
    }

    http {
        server {
            listen 80;

            location / {
                proxy_pass http://app:5000; # 'app' is the service name for our Flask app
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
            }
        }
    }
    ```

    Notice `proxy_pass http://app:5000;`. Here, app refers to the Docker Compose service name for our Flask application. Nginx will forward requests to port 5000 of the `app` container.

6. **Create the** `docker-compose.yml` **file**:

    ```Bash
    nano docker-compose.yml
    ```

    **Paste the following content**:

    ```YAML
    version: '3.8'

    services:
      web:
        image: nginx:latest
        ports:
          - "80:80"
        volumes:
          - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro # Mount Nginx config
        depends_on:
          - app # 'web' depends on 'app' to be ready
        networks:
          - app_network

      app:
        build: . # Build Docker image from current directory (where Dockerfile is)
        environment:
          DB_HOST: db # Connect to 'db' service by its name
          DB_PORT: 5432
        networks:
          - app_network
          - db_network

      db:
        image: postgres:13
        environment:
          POSTGRES_DB: mydatabase
          POSTGRES_USER: user
          POSTGRES_PASSWORD: mysecretpassword
        volumes:
          - db_data:/var/lib/postgresql/data # Persistent data for DB
        networks:
          - db_network

    volumes:
      db_data: # Declare the named volume

    networks:
      app_network:
      db_network:
    ```

**Key additions in this** `docker-compose.yml`:

- `build: .`: For the `app` service, instead of `image:`, we use `build: .`. This tells Docker Compose to build the Docker image for this service using the `Dockerfile` found in the current directory.
- `depends_on:`: In the `web` service, `depends_on: - app` signifies that the `web` service will only start after the `app` service has started. While this doesn't wait for the application inside the container to be fully ready, it helps ensure the order of container startup.
- **Multiple Networks**: We use `app_network` for `web` and `app`, and `db_network` for `app` and `db`, demonstrating network segmentation.
- **Environment Variables for** `app`: The Flask app reads `DB_HOST` and `DB_PORT` from its environment. Docker Compose sets `DB_HOST` to `db` (the service name of our PostgreSQL container) and `DB_PORT` to `5432` (PostgreSQL's default port).

**Scaling Services**:

One of the significant advantages of Docker Compose is the ability to easily scale services. For example, to run multiple instances of your `app` service to handle more requests, you can use the `scale` command:

```Bash
docker compose up -d
docker compose ps # See initial state
docker compose up -d --scale app=3 # Scale 'app' service to 3 instances
docker compose ps # See the 3 'app' instances
```

This command will create two additional `app` containers, distributing the load across them (though for proper load balancing with Nginx, you'd need more advanced Nginx configuration, which is beyond this lesson's scope).

To bring everything down, you would still use `docker compose down`.

This example demonstrates how Docker Compose integrates different components of an application stack and allows for scaling.

### Troubleshooting

Even with carefully crafted `docker-compose.yml` files, issues can arise. Effective troubleshooting is a critical skill for any system administrator. Here are some common techniques and commands you can use when things don't go as planned:

1. **Check Service Status (**`docker compose ps`**)**:
   - **Purpose**: This is your first stop. It quickly shows which services are running, which have exited, and their current state.
   - **What to look for**: A service in an `Exited` state often indicates an issue. Check the `Exit` code and `Status` column for clues. For example, `(1)` usually means a general error, while `(137)` might suggest an out-of-memory error.

2. **Review Logs (**`docker compose logs`**)**:
    - **Purpose**: The most important tool for diagnosing problems. Application and service errors are typically logged to standard output (`stdout`) and standard error (`stderr`).
    - **What to look for**: Error messages, stack traces, warnings, or any unexpected output.
    - **Usage considerations**:
        - `docker compose logs <service_name>`: Focus on logs from a specific service.
        - `docker compose logs -f <service_name>`: Follow logs in real-time.
        - `docker compose logs --tail 50 <service_name>`: View only the last 50 lines.
        - `docker compose logs --since 1h <service_name>`: View logs from the last hour.

3. **Inspect Container Details (**`docker inspect`**)**:
    - **Purpose**: Provides a low-level view of a container's configuration, network settings, mounted volumes, and more.
    - **Usage**: First, get the container ID or name from `docker compose ps` or `docker ps`.

        ```Bash
        docker inspect <container_id_or_name>
        ```

    - **What to look for**: Mismatched port mappings, incorrect volume mounts, wrong environment variables, or unexpected network configurations.

4. **Check Network Connectivity**:
    - **Purpose**: If services can't communicate, it's often a networking issue.
    - **Technique**:
        - Use ping or curl from inside one container to another. To do this, you first need to execute a shell inside a running container:

            ```Bash
            docker exec -it <container_id_or_name> bash # or sh, or alpine/busybox
            ```

            Once inside, try to ping the hostname of the service you're trying to reach (which is its service name in docker-compose.yml). For example, from the app container, you might ping db. If ping isn't available, apt update && apt install iputils-ping or apk add iputils might be needed.

        - Verify port accessibility from the host to the container using `netstat` or `ss` on the host, or `simply curl localhost:<port>` if the port is exposed.

5. **Rebuild Images/Clear Cache (**`docker compose build --no-cache`**,** `docker system prune`**)**:
    - **Purpose**: Sometimes, a cached layer in a Docker image can cause issues, or old exited containers might be consuming resources.
    - **Usage**:
        - If you've changed a `Dockerfile` and `docker compose up` isn't picking up the changes, use: `docker compose build --no-cache <service_name>` (or all services)
        - To clean up old images, containers, and volumes not used by any running containers: `docker system prune -a` (use with caution, this removes a lot)

6. **Validate** `docker-compose.yml` **Syntax**:
    - **Purpose**: A common source of error for beginners. YAML is sensitive to indentation.
    - **Technique**: Use a YAML linter online, or rely on Docker Compose's error messages which are usually quite descriptive if there's a syntax issue during `docker compose up`.

**A Practical Troubleshooting Workflow**:

1. **Issue Identified**: Application not working, service not starting.
2. **Check** `docker compose ps`: See which services are healthy and which are not.
3. **Check** `docker compose logs <problematic_service>`: Look for immediate errors.
4. **If no clear error**: `docker inspect` the problematic container.
5. **If inter-service communication suspected**: `docker exec` into a container and try pinging the other service.
6. **If code/image issue suspected**: Rebuild with `--no-cache`.

Troubleshooting Docker Compose applications is much like troubleshooting any other application, but with the added layer of containerization. The key is to methodically isolate the problem using the available tools.
